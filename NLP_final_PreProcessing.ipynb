{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "NLP_final_PreProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YNRfp3WOEA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g4eQL7U4yld",
        "colab_type": "code",
        "outputId": "9d03455c-9337-42d5-c664-321ec75277c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB5cntrzksNO",
        "colab_type": "text"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEFHr_DTdIu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COLS = ['cuisine', 'title', 'ingredients', 'process', 'instructions', 'keto', 'healthScore', 'diets', 'nutritions']\n",
        "data = pd.read_csv('/content/drive/My Drive/Study @ Fordham/NLP Project/nlp_finalproj_data_temp.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lb3B42I5hmc",
        "colab_type": "code",
        "outputId": "6b2de024-a510-4bcc-a240-4d3c01b94fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "data['cuisine'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Middle Eastern    200\n",
              "French            200\n",
              "Mediterranean     200\n",
              "Vietnamese        200\n",
              "Chinese           200\n",
              "Italian           200\n",
              "African           123\n",
              "Indian             99\n",
              "Name: cuisine, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwOCcOWTkybw",
        "colab_type": "text"
      },
      "source": [
        "# Encode and seperate features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIygOuolB-no",
        "colab_type": "code",
        "outputId": "eeb7c41b-2023-4d77-d207-92f892b8c2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import re\n",
        "\n",
        "from sklearn import preprocessing\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGsAmmm2NtjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deduplicate(ingredient):\n",
        "    # try to uniform the duplicated or similar ingredients\n",
        "    ingredient = re.sub('canned |fresh |cooked |dried |dry |ground |refrigerated |light |ready-to-use ', '', ingredient)\n",
        "    ingredient = re.sub('lettuc[^0-9]+', 'lettuc', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ salt', 'salt', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ basil|basil [^0-9]+', 'basil', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ bacon|bacon [^0-9]+', 'bacon', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ thyme|thyme [^0-9]+', 'thyme', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ cilantro|cilantro [^0-9]+', 'cilantro', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ parsley|parsley [^0-9]+', 'parsley', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ cinnamon|cinnamon [^0-9]+', 'cinnamon', ingredient)\n",
        "    ingredient = re.sub('cream[^0-9]+chees|cream chees[^0-9]+', 'cream chees', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+parmesan[^0-9]+', 'parmesan chees', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ peanut butt', 'peanut butt', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ chili pepper', 'chili pepp', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ nectar', 'nectar', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ tofu', 'tofu', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ tomato', 'tomato', ingredient)\n",
        "    ingredient = re.sub('[^0-9]+ bell pepp', 'bell pepp', ingredient)\n",
        "    ingredient = re.sub('egg roll wra[^0-9]+', 'egg roll wrap', ingredient)\n",
        "    return ingredient\n",
        "\n",
        "\n",
        "def clean_data(igd_data):\n",
        "    # igd_data: a array-like object which contains all ingredients list of training dataset\n",
        "    # stem: boolean, default to be True\n",
        "    # *output: a dict\n",
        "    igds = list()\n",
        "    raw_igds = igd_data.split(sep=',')\n",
        "    for i in raw_igds:\n",
        "        igds.append(re.sub(' *\\'|\\[|\\]|\\ *\"', '', i)) # delete unneeded punctuations\n",
        "    return igds\n",
        "\n",
        "def stem_and_deduplicate(igd_data):\n",
        "    ps = PorterStemmer()\n",
        "    stem_igds = [ps.stem(x) for x in igd_data]\n",
        "    return [deduplicate(y) for y in stem_igds]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUkZHN7qwan6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split and encode ingredients\n",
        "\n",
        "all_ingredients = [stem_and_deduplicate(clean_data(x)) for x in data['ingredients']]\n",
        "\n",
        "le_igd = preprocessing.LabelEncoder()\n",
        "le_igd.fit(np.hstack(all_ingredients))\n",
        "\n",
        "data['encoded_ingredients'] = [le_igd.transform(x) for x in all_ingredients]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr2ISuPm7eQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate the ingredients and process\n",
        "\n",
        "# Split the process\n",
        "ps = PorterStemmer()\n",
        "process = list()\n",
        "for i in range(len(data)):\n",
        "    tem = data['process'][i].split(sep=', [')\n",
        "    tokens = [re.sub(' *\\'|\\[|\\]|\\ *\"', '', i).replace(',', ' ') for i in tem]\n",
        "    process.append([ps.stem(x) for x in tokens])\n",
        "\n",
        "# Link them\n",
        "process_igds = []\n",
        "for (n, left) in enumerate(process):\n",
        "    right = all_ingredients[n]\n",
        "    piece = []\n",
        "    for (i, p) in enumerate(left):\n",
        "        piece.append(p+' '+right[i])\n",
        "    process_igds.append(piece)\n",
        "\n",
        "data['process ingredients'] = process_igds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSN0HPcXcJ2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_methods(methods_data, stopwords):\n",
        "    tokens = word_tokenize(str(methods_data).lower())\n",
        "    tagged_ins = nltk.pos_tag(tokens)\n",
        "    methods = set()\n",
        "    ps = PorterStemmer()\n",
        "    for (m, tag) in tagged_ins:\n",
        "        if tag in ['VB']: # NOT decided if to take NN in\n",
        "            methods.add(ps.stem(m))\n",
        "    effective_methods = [w for w in methods if not w in stopwords]\n",
        "    return effective_methods"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_LBuXWPNQM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split and encode methods (from instructions)\n",
        "\n",
        "freq_vb = ['put', 'add', 'use', 'keep', 'prepar', 'start']\n",
        "\n",
        "data['instructions'] = [extract_methods(x, freq_vb) for x in data['instructions']]\n",
        "\n",
        "# Encode the instructions words\n",
        "le_methods = preprocessing.LabelEncoder()\n",
        "le_methods.fit(np.hstack(data['instructions']))\n",
        "\n",
        "data['encoded_instructions'] = [le_methods.transform(x) for x in data['instructions']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNAdZCu5OXOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split and encode diets\n",
        "\n",
        "all_diets = [stem_and_deduplicate(clean_data(x)) for x in data['diets']]\n",
        "\n",
        "le_diets = preprocessing.LabelEncoder()\n",
        "le_diets.fit(np.hstack(all_diets))\n",
        "le_diets.classes_\n",
        "\n",
        "data['encoded_diets'] = [le_diets.transform(x) for x in all_diets]\n",
        "\n",
        "# Dict for search\n",
        "code2diets = {x:n for n,x in zip(range(10),le_diets.classes_.tolist())}\n",
        "\n",
        "diet_info = np.zeros((len(data), 11))\n",
        "for i in le_diets.classes_.tolist():\n",
        "    for (num, recipe_info) in enumerate(data['encoded_diets']):\n",
        "        for diet in recipe_info:\n",
        "            diet_info[int(num), int(diet)] = 1\n",
        "\n",
        "diet_names = le_diets.classes_.tolist()\n",
        "diet_names[0] = 'no diet'\n",
        "\n",
        "diet_info = pd.DataFrame(diet_info, columns=diet_names)\n",
        "data = data.join(diet_info)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OaTPajkQbS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seperate nutrition feature into three columns\n",
        "\n",
        "tem = []\n",
        "for n in data['nutritions']:\n",
        "    numberonly = re.sub(' *\\'|\\{|\\}|\\ *\"|[a-z|A-Z]|:', '', n)\n",
        "    ns = re.split(r',', numberonly)\n",
        "    tem.append(ns)\n",
        "\n",
        "data['protein'], data['fat'], data['carbs'] = [float(x[0]) for x in tem], [float(x[1]) for x in tem], [float(x[2]) for x in tem]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEMFmj4PI0eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the preprocessed data\n",
        "\n",
        "data.to_csv('nlp_finalproj_data_preprocessed.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}